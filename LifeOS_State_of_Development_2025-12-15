2025-12-15 Gemini CLI — Life OS Development — What Exists?

I've reviewed the previous session's progress and the remaining tasks. My next step, as per your request, is to decide what data exists and how it   flows within LifeOS.

  This involves identifying the core types of information the system will
  manage and how they move through it, from creation to storage, processing,
  and display. Given the event-sourced architecture outlined in the
  Agentic_AI_Coder_Master_Instructions, the data flow will be heavily
  influenced by events.

  Decision: LifeOS Data Model and Flow

  Plain-Language Explanation:

  Imagine LifeOS as a smart journal that constantly learns from you. At its
  heart, it deals with several key types of information, or "data entities."
  These are the fundamental building blocks of your personal system:

   1. Events: This is the most crucial type of data. Every significant action
      you take or change in your life that LifeOS tracks (like logging an
      emotion, completing a task, or creating a new knowledge note) is
      recorded as an immutable "event." Think of it like a never-ending tape
      recording of your life's key moments. Events are the source of truth for
      everything else in LifeOS.
       * Flow: You interact with the system (e.g., through the UI), which
         triggers an event. This event is immediately saved to a special
         "event log" in the database.

   2. Core Entities (Your Personal Data): These are the things you actively
      manage and reflect on. They are derived from the stream of events.
      Examples include:
       * Emotion Entries: How you're feeling (mood, energy, specific
         emotions).
       * Contact Profiles: Information about the people in your life and your
         interactions.
       * Task Items: Your to-dos, organized by GTD/PARA principles.
       * Knowledge Nodes (Zettels): Your personal notes, insights, and
         captured information.
       * System Insights: AI-generated observations or patterns derived from
         your data.
       * Projects/Areas/Resources/Archives (PARA): Organizational structures
         for your knowledge and tasks.
       * Reflections: Guided self-assessment and journaling entries.

       * Flow: When new events (like "EmotionLogged" or "TaskCreated") are
         recorded, a special "event processor" reads them from the event log.
         This processor then updates simplified versions of your core
         entities, called "read models," which are stored in a separate,
         faster-to-query database (like a normal relational database). This
         way, when you want to see your current task list or a summary of your
         emotions, the system can quickly pull that information from the read
         models without having to replay the entire event history every time.

   3. Derived Data (AI Context & Insights): This data is generated by LifeOS's
      AI components to help you.
       * Vector Embeddings: Numerical representations of your text data
         (notes, reflections, conversations) that allow AI to find
         semantically similar information quickly.
       * Graph Data: Connections between your different pieces of data (e.g.,
         this task is related to that knowledge note, this person is connected
         to this project).
       * AI Insights & Nudges: The actual recommendations, observations, and
         prompts generated by the AI based on your core entities and event
         history.

       * Flow: The event processor might also send relevant data to
         specialized AI services. For instance, when a new knowledge note
         event occurs, the text is sent to a "vectorization service" which
         creates a numerical embedding and stores it in a vector database.
         Similarly, relationships identified in your data could be stored in a
         graph database. When the AI needs to generate an insight or a nudge,
         it queries these derived data stores (vector, graph, and read models)
         to get the most relevant context, processes it, and then generates a
         new "InsightGenerated" or "NudgeProposed" event.

  Data Flow Summary (Simplified):

   1. User Action/System Event: You do something in the UI, or an internal
      system process triggers.
   2. Event Creation: A new, immutable event (e.g., EmotionLogged,
      TaskCreated) is generated.
   3. Event Log: The event is written immediately to an append-only SQLite
      event_log. This is the single source of truth.
   4. Event Processing: An Event Processor continuously reads new events from
      the event_log.
   5. Read Model Updates: The Event Processor updates simplified,
      query-optimized "read models" (e.g., EmotionReadModel, TaskReadModel) in
      a relational database (SQLite). This allows for fast querying of current
      state.
   6. Derived Data Updates: The Event Processor also pushes data to
      specialized AI components:
       * Vector Store (Qdrant): For semantic search and retrieval (e.g., what
         notes are similar to this idea?).
       * Graph Store (ArangoDB): For understanding relationships and
         connections between entities (e.g., what tasks are blocked by whom?).
   7. AI Services (Ollama/LangChain/LlamaIndex): These services query the read
      models, vector store, and graph store to get context.
   8. Insight/Nudge Generation: The AI processes the context and generates
      insights or proposes nudges.
   9. New Events: These insights or nudges are themselves recorded as new
      events in the event_log (e.g., InsightGenerated, NudgeProposed).
   10. UI Display: The UI queries the read models to display the current state
       of your data, tasks, emotions, and AI insights.
  This architecture ensures that your data is never lost (due to the
  append-only event log), can be easily rebuilt, and is optimized for both
  rapid querying and advanced AI processing.

  Written Specification for AI Coders: Data Model and Flow

  Goal: To define the primary data entities within LifeOS and their lifecycle,
  emphasizing the event-sourced architecture.

  Specifications:

   1. Event Log (Source of Truth):
       * All state changes MUST originate as discrete, immutable Event
         objects.
       * Event structure: event_id, event_type, timestamp, payload (JSON),
         schema_version.
       * Events MUST be written to an append-only SQLite database
         (event_log.db).
       * Direct writes to read_models or derived_data stores are FORBIDDEN;
         all changes MUST flow through the event processor.

   2. Core Entities (Pydantic Models):
       * Define Pydantic models for all core entities in
         apps/backend/lifeos-rag-api/models/. These will represent the
         conceptual structure of data.
       * Initial core entities include, but are not limited to:
           * EmotionEntry
           * ContactProfile
           * TaskItem
           * KnowledgeNode (Zettel)
           * SystemInsight
           * Project
           * Area
           * Resource
           * Reflection
       * These Pydantic models MUST be accompanied by corresponding JSON
         schemas in temp_schemas/ and registered in a JSON Schema Registry for
         versioning and validation.

   3. Read Models (SQLAlchemy):
       * For each core entity, define a corresponding SQLAlchemy model in
         apps/backend/lifeos-rag-api/src/event_sourcing/read_models.py.
       * These models represent the current, aggregated state of entities,
         derived from events.
       * They MUST be stored in a separate SQLite database (read_models.db)
         for fast querying.
       * Updates to read models MUST ONLY occur via the Event Processor.

   4. Event Processor:
       * A dedicated service
         (apps/backend/lifeos-rag-api/src/event_sourcing/event_processor.py)
         will continuously consume new events from the event_log.
       * Upon consuming an event, the processor will:
           * Update relevant read models.
           * Dispatch data to Derived Data Stores as necessary.

   5. Derived Data Stores:
       * Vector Store (Qdrant - MIT Licensed):
           * Stores vector embeddings of KnowledgeNode content, Reflection
             entries, and other text-based data requiring semantic search.
           * Updates triggered by Event Processor when relevant events occur
             (e.g., KnowledgeNodeCreated, ReflectionUpdated).
       * Graph Store (ArangoDB - Apache 2.0 Licensed):
           * Stores relationships between core entities (e.g., TaskItem linked
             to KnowledgeNode, ContactProfile related to Reflection).
           * Updates triggered by Event Processor for relationship-defining
             events.

   6. AI Context & Retrieval Flow:
       * AI services (LlamaIndex, LangChain) will retrieve context by
         querying:
           * Read Models (for current entity state).
           * Vector Store (for semantic similarity).
           * Graph Store (for relational context).
       * Retrieval MUST adhere to Context Decay rules and Attention Rules
         (e.g., only active projects included by default).
       * Any AI-generated content (insights, nudges) MUST be formalized as new
         events and written to the event_log.

  This sets the stage for how information is structured and moves throughout
  the LifeOS system. Next, we will tackle choosing a minimal, coherent tech
  stack.
